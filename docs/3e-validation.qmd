---
title:  "Cross Validation"
author: <br><br><br><br><span style="font-family:perpetua; font-variant:small-caps; color:#606060;">Kerry Back</span><br><br><img src="RiceBusiness-transparent-logo-sm.png"  height=80>
execute:
  echo: false
  jupyter: python3
  cache: true
format: 
  revealjs:
    highlight-style: monokai
    code-fold: true
    code-copy: hover
    scrollable: true
    slide-number: true
    preview-links: true
    self-contained: true
    controls: true
    transition: fade
    theme: [solarized, 2023.scss]
    incremental: true
---

##

- Cross-validation (CV) is a way to choose optimal hyperparameters using the training data
- Split the training data into subsets, e.g., A, B, C, D, E
- Define a finite set of hyperparemeter combinations (a grid) to choose from
  - Example: {"max_depth": [3, 4], "learning_rate": [0.05, 0.1]}
  - Example: {"hidden_layer_sizes:[[4, 2], [8, 4, 2], [16, 8, 4]]}

## 

- Use one of the subsets (e.g., A) as the validation set
- Train with each of the hyperparameter combinations on the union of the remaining subsets (e.g., B $\cup$ C $\cup$ D $\cup$ E)
- Compute the trained model scores on A
- Repeat with B as the validation set, etc.
- For each hyperparameter combination, end up with as many validation scores as there are subsets

##

- Average the validation scores to get a single score for each hyperparameter combination
- Choose the hyperparameters with the highest average score
- All of this together is "search over the grid using cross-validation to find the best hyperparameters"
- It is implemented by scikit-learn's GridSearchCV function

## Custom scoring function

- If we want to use predictions to sort stocks into "good" and "bad", then MSE is a poor scoring method.
- Example: if you buy a stock because the predicted return is 40% and the actual return turns out to be 100%, is that really an error?
- We want higher predictions to correspond to higher actual returns, so rank correlation would be a reasonable scoring method.

## Coding a custom scoring function

. . .

```.p
from scipy.stats import spearmanr
from sklearn.metrics import make_scorer
score = make_scorer(spearmanr, greater_is_better=True)
```

```{python}
from scipy.stats import spearmanr
from sklearn.metrics import make_scorer
scorer = make_scorer(lambda a, b: spearmanr(a, b), greater_is_better=True)
```

- We can pass this to GridSearchCV to choose the best hyperparameters.

## Example

- Same data as in 3a-trees
  - agr, bm, idiovol, mom12m, roeq
  - training data = 2021-12
  - test data = 2022-01
- Quantile transform features and ret in each cross-section



```{python}
from sqlalchemy import create_engine
import pymssql
import pandas as pd

server = "mssql-82792-0.cloudclusters.net:16272"
username = "user"
password = "RiceOwls1912" # paste password between quote marks
database = "ghz"

string = "mssql+pymssql://" + username + ":" + password + "@" + server + "/" + database

conn = create_engine(string).connect()

df = pd.read_sql(
    """
    select ticker, date, agr, bm, idiovol, mom12m, roeq, ret
    from data
    where date in ('2021-12', '2022-01')
    """, 
    conn
)
features = ["agr", "bm", "idiovol", "mom12m", "roeq"]
df = df.dropna()
```



```{python}
from sklearn.preprocessing import QuantileTransformer
qt = QuantileTransformer(output_distribution="normal")
def qtxs(d):
    x = qt.fit_transform(d)
    return pd.DataFrame(x, columns=d.columns, index=d.index)

df[features+["ret"]] = df.groupby(
  "date", 
  group_keys=False
)[features+["ret"]].apply(qtxs)
```

## Cross validation for gradient boosting

. . .

```{.p code-line-numbers="1|3-4|6-9|10"}
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor

model = GradientBoostingRegressor()
```

##

. . .

```.p
param_grid = {
  "random_state": [0],
  "max_depth": [3, 4], 
  "learning_rate": [0.05, 0.1]
}
cv = GridSearchCV(
  estimator=model,
  param_grid=param_grid,
  scoring=scorer
)
```

## {.smaller}

. . .

```.p
cv.fit(Xtrain, ytrain)
pd.DataFrame(cv.cv_results_).iloc[:, 4:]
```

. . .

```{python}
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor

model = GradientBoostingRegressor()

Xtrain = df[df.date=='2021-12'][features]
ytrain = df[df.date=='2021-12']["ret"]

param_grid = {
  "random_state": [0],
  "max_depth": [3, 4], 
  "learning_rate": [0.05, 0.1]
}

cv = GridSearchCV(
  model,
  param_grid=param_grid,
)

cv.fit(Xtrain, ytrain)
pd.DataFrame(cv.cv_results_).iloc[:, 4:]
```

## Cross validate AdaBoost

. . .

```.p
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor

model = AdaBoostRegressor(
    base_estimator=DecisionTreeRegressor()
)
```

## 

. . .

```.p
param_grid = {
  "base_estimator__random_state": [0],
  "base_estimator__max_depth": [3, 4],
  "learning_rate": [0.1, 0.2]
}

cv = GridSearchCV(
  model,
  param_grid=param_grid
)
```

## {.smaller}

. . .

```.p
cv.fit(Xtrain, ytrain)
pd.DataFrame(cv.cv_results_).iloc[:, 4:]
```

. . .

```{python}
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor

model = AdaBoostRegressor(
    base_estimator=DecisionTreeRegressor()
)

param_grid = {
  "base_estimator__random_state": [0],
  "base_estimator__max_depth": [3, 4],
  "learning_rate": [0.1, 0.2]
}

cv = GridSearchCV(
  model,
  param_grid=param_grid
)
cv.fit(Xtrain, ytrain)
pd.DataFrame(cv.cv_results_).iloc[:, 4:]
```
